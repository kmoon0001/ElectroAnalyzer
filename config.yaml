analysis:
  chunk_overlap: 100
  confidence_threshold: 0.75
  deterministic_focus: '- Treatment frequency documented\n- Goals reviewed or adjusted\n-
    Medical necessity justified'
  max_document_length: 50000
use_ai_mocks: false
auth:
  access_token_expire_minutes: 30
  algorithm: HS256
database:
  echo: false
  url: sqlite:///./compliance.db
  pool_size: 10
  max_overflow: 20
  pool_timeout: 30
  pool_recycle: 3600
  sqlite_optimizations: true
  connection_timeout: 20
enable_director_dashboard: true
habits_framework:
  enabled: true
  visibility_level: moderate
  ai_features:
    use_ai_mapping: true
    enable_gamification: true
    privacy_mode: false
  report_integration:
    include_habits_section: true
    show_habit_tags: true
    habit_confidence_threshold: 0.7
  dashboard_integration:
    show_progress_tracking: true
    show_achievements: true
    show_recommendations: true

# RAG System Configuration
rag_system:
  enabled: true
  strictness_adaptive: true
  knowledge_sources:
    clinical_guidelines: true
    compliance_rubrics: true
    medical_dictionaries: true
    fact_checking_database: true
    historical_analyses: true
    expert_rules: true
  rag_caching:
    enabled: true
    cache_embeddings: true
    cache_retrievals: true
    cache_fact_checks: true
    cache_knowledge: true
    ttl_hours: 24
llm:
  context_length: 1024
  gpu_layers: 0
  threads: 2
  hf_model_type: llama
  model_type: ctransformers
  model_repo_id: llama
  generation_params:
    max_new_tokens: 256
    repeat_penalty: 1.1
    stop_sequences:
    - </analysis>
    - \n\n---
    temperature: 0.05
    top_p: 0.9
maintenance:
  purge_interval_days: 1
  purge_retention_days: 30
  in_memory_retention_minutes: 60
  in_memory_purge_interval_seconds: 300
models:
  analysis_prompt_template: src/resources/prompts/analysis_prompt_template.txt
  doc_classifier_prompt: src/resources/prompts/doc_classifier_prompt.txt
  fact_checker: google/flan-t5-small
  fact_checker_backend: llm
  generator: llama-local
  generator_filename: tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
  generator_local_path: models/tinyllama
  generator_profiles:
    cpu_llama32_q4:
      repo: llama
      filename: tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
      max_system_gb: 64.0
      optimize_for_speed: true
      fast_mode: true
  ner_ensemble:
  - OpenMed/OpenMed-NER-PathologyDetect-PubMed-v2-109M
  - d4data/biomedical-ner-all
  nlg_prompt_template: src/resources/prompts/nlg_prompt_template.txt
  optimization:
    cache_models: true
    compile_models: true
    optimize_for_inference: true
    use_better_transformer: true
    use_flash_attention: true
  reranker: cross-encoder/ms-marco-MiniLM-L-6-v2
  retriever: pritamdeka/S-PubMedBert-MS-MARCO
paths:
  api_url: http://127.0.0.1:8001
  cache_dir: .cache
  logs_dir: logs
  medical_dictionary: src/resources/medical_dictionary.txt
  rule_dir: ./src/resources
  temp_upload_dir: ./temp
performance:
  batch_processing: true
  batch_size: 4
  context_optimization: true
  enable_caching: true
  fast_mode: true
  gpu_acceleration: false
  gradient_checkpointing: false
  inference_optimization: true
  max_chunk_size: 2000
  max_workers: 1
  memory_efficient_mode: true
  memory_optimization: true
  mixed_precision: false
  model_quantization: true
  optimized_chunking: true
  overlap_size: 200
  skip_advanced_ner: false
  skip_fact_checking: false
  enable_deep_fact_checking: false
  rag_fact_checking:
    similarity_threshold: 0.7
    rerank_threshold: 0.8
  parallel_processing: true
  reduce_context_window: false
  simple_report_mode: false
  smart_caching: true
retrieval:
  batch_size: 8
  dense_model_name: pritamdeka/S-PubMedBert-MS-MARCO
  max_sequence_length: 256
  rrf_k: 60
  similarity_top_k: 5
use_ai_mocks: false
log_level: INFO
