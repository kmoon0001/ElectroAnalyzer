src/core/build_bm25_index.py:3: error: Skipping analyzing "rank_bm25": module is installed, but missing library stubs or py.typed marker  [import-untyped]
src/core/build_bm25_index.py:3: note: See https://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports
src/core/smart_chunker.py:1: error: Skipping analyzing "nltk": module is installed, but missing library stubs or py.typed marker  [import-untyped]
src/core/smart_chunker.py:17: error: Incompatible default for argument "metadata" (default has type "None", argument has type "dict[Any, Any]")  [assignment]
src/core/smart_chunker.py:17: note: PEP 484 prohibits implicit Optional. Accordingly, mypy has changed its default to no_implicit_optional=True
src/core/smart_chunker.py:17: note: Use https://github.com/hauntsaninja/no_implicit_optional to automatically upgrade your codebase
src/core/llm_service.py:2: error: Skipping analyzing "ctransformers": module is installed, but missing library stubs or py.typed marker  [import-untyped]
src/core/llm_service.py:48: error: "None" not callable  [misc]
src/crud.py:68: error: Incompatible types in assignment (expression has type "str", variable has type "Column[str]")  [assignment]
src/crud.py:75: error: Need type annotation for "summary" (hint: "summary: dict[<type>, <type>] = ...")  [var-annotated]
src/crud.py:78: error: "ColumnElement[Any]" has no attribute "__iter__" (not iterable)  [attr-defined]
src/rubric_router.py:5: error: Module "src.models" has no attribute "RubricCreate"  [attr-defined]
src/rubric_router.py:6: error: Module "src.database" has no attribute "DATABASE_PATH"  [attr-defined]
src/auth.py:50: error: Incompatible types in assignment (expression has type "Any | None", variable has type "str")  [assignment]
src/auth.py:57: error: Argument "username" to "get_user_by_username" has incompatible type "str | None"; expected "str"  [arg-type]
src/api/routers/health.py:17: error: No overload variant of "execute" of "Session" matches argument type "str"  [call-overload]
src/api/routers/health.py:17: note: Possible overload variants:
src/api/routers/health.py:17: note:     def [_T: Any] execute(self, statement: TypedReturnsRows[_T], params: Sequence[Mapping[str, Any]] | Mapping[str, Any] | None = ..., *, execution_options: _OrmKnownExecutionOptions | Mapping[str, Any] = ..., bind_arguments: dict[str, Any] | None = ..., _parent_execute_state: Any | None = ..., _add_event: Any | None = ...) -> Result[_T]
src/api/routers/health.py:17: note:     def execute(self, statement: UpdateBase, params: Sequence[Mapping[str, Any]] | Mapping[str, Any] | None = ..., *, execution_options: _OrmKnownExecutionOptions | Mapping[str, Any] = ..., bind_arguments: dict[str, Any] | None = ..., _parent_execute_state: Any | None = ..., _add_event: Any | None = ...) -> CursorResult[Any]
src/api/routers/health.py:17: note:     def execute(self, statement: Executable, params: Sequence[Mapping[str, Any]] | Mapping[str, Any] | None = ..., *, execution_options: _OrmKnownExecutionOptions | Mapping[str, Any] = ..., bind_arguments: dict[str, Any] | None = ..., _parent_execute_state: Any | None = ..., _add_event: Any | None = ...) -> Result[Any]
src/api/routers/admin.py:72: error: Incompatible types in assignment (expression has type "bool", variable has type "Column[bool]")  [assignment]
src/api/routers/admin.py:88: error: Incompatible types in assignment (expression has type "bool", variable has type "Column[bool]")  [assignment]
src/core/ner.py:27: error: No overload variant of "pipeline" matches argument types "str", "Any", "Any", "str"  [call-overload]
src/core/ner.py:27: note: Possible overload variants:
src/core/ner.py:27: note:     def pipeline(task: None, model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> Pipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['audio-classification'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> AudioClassificationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['automatic-speech-recognition'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> AutomaticSpeechRecognitionPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['depth-estimation'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> DepthEstimationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['document-question-answering'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> DocumentQuestionAnsweringPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['feature-extraction'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> FeatureExtractionPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['fill-mask'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> FillMaskPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['image-classification'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> ImageClassificationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['image-feature-extraction'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> ImageFeatureExtractionPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['image-segmentation'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> ImageSegmentationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['image-text-to-text'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> ImageTextToTextPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['image-to-image'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> ImageToImagePipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['image-to-text'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> ImageToTextPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['keypoint-matching'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> KeypointMatchingPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['mask-generation'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> MaskGenerationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['object-detection'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> ObjectDetectionPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['question-answering'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> QuestionAnsweringPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['summarization'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> SummarizationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['table-question-answering'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> TableQuestionAnsweringPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['text-classification'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> TextClassificationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['text-generation'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> TextGenerationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['text-to-audio'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> TextToAudioPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['text2text-generation'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> Text2TextGenerationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['token-classification'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> TokenClassificationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['translation'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> TranslationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['video-classification'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> VideoClassificationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['visual-question-answering'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> VisualQuestionAnsweringPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['zero-shot-audio-classification'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> ZeroShotAudioClassificationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['zero-shot-classification'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> ZeroShotClassificationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['zero-shot-image-classification'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> ZeroShotImageClassificationPipeline
src/core/ner.py:27: note:     def pipeline(task: Literal['zero-shot-object-detection'], model: str | PreTrainedModel | TFPreTrainedModel | None = ..., config: str | PretrainedConfig | None = ..., tokenizer: str | PreTrainedTokenizer | PreTrainedTokenizerFast | None = ..., feature_extractor: str | Any | None = ..., image_processor: str | BaseImageProcessor | None = ..., processor: str | ProcessorMixin | None = ..., framework: str | None = ..., revision: str | None = ..., use_fast: bool = ..., token: str | bool | None = ..., device: int | str | device | None = ..., device_map: str | dict[str, int | str] | None = ..., dtype: str | dtype | None = ..., trust_remote_code: bool | None = ..., model_kwargs: dict[str, Any] | None = ..., pipeline_class: Any | None = ..., **kwargs: Any) -> ZeroShotObjectDetectionPipeline
src/parsing.py:7: error: Skipping analyzing "pytesseract": module is installed, but missing library stubs or py.typed marker  [import-untyped]
src/parsing.py:69: error: Incompatible types in assignment (expression has type "Image", variable has type "ImageFile")  [assignment]
src/guideline_service.py:14: error: Skipping analyzing "faiss": module is installed, but missing library stubs or py.typed marker  [import-untyped]
src/guideline_service.py:128: error: "None" has no attribute "add"  [attr-defined]
src/guideline_service.py:194: error: Incompatible default for argument "top_k" (default has type "None", argument has type "int")  [assignment]
src/guideline_service.py:194: note: PEP 484 prohibits implicit Optional. Accordingly, mypy has changed its default to no_implicit_optional=True
src/guideline_service.py:194: note: Use https://github.com/hauntsaninja/no_implicit_optional to automatically upgrade your codebase
src/core/hybrid_retriever.py:3: error: Skipping analyzing "rank_bm25": module is installed, but missing library stubs or py.typed marker  [import-untyped]
src/core/hybrid_retriever.py:55: error: Module has no attribute "get_rubrics"  [attr-defined]
src/core/document_analysis_service.py:3: error: Skipping analyzing "faiss": module is installed, but missing library stubs or py.typed marker  [import-untyped]
src/core/document_analysis_service.py:58: error: Incompatible default for argument "metadata_filter" (default has type "None", argument has type "dict[Any, Any]")  [assignment]
src/core/document_analysis_service.py:58: note: PEP 484 prohibits implicit Optional. Accordingly, mypy has changed its default to no_implicit_optional=True
src/core/document_analysis_service.py:58: note: Use https://github.com/hauntsaninja/no_implicit_optional to automatically upgrade your codebase
src/api/routers/analysis.py:94: error: Argument 4 to "add_task" of "BackgroundTasks" has incompatible type "str | None"; expected "str"  [arg-type]
src/gui/main_window.py:15: error: Module "src.gui.dialogs.login_dialog" has no attribute "LoginDialog"  [attr-defined]
src/gui/main_window.py:173: error: "QTextEdit" has no attribute "setOpenExternalLinks"  [attr-defined]
src/gui/main_window.py:174: error: "QTextEdit" has no attribute "anchorClicked"  [attr-defined]
src/gui/main_window.py:193: error: Item "None" of "QTextDocument | None" has no attribute "find"  [union-attr]
src/gui/main_window.py:196: error: Item "None" of "QTextDocument | None" has no attribute "find"  [union-attr]
src/gui/main_window.py:275: error: Cannot assign to a method  [method-assign]
src/gui/main_window.py:275: error: Incompatible types in assignment (expression has type "QThread", variable has type "Callable[[], QThread | None]")  [assignment]
src/gui/main_window.py:276: error: Missing positional arguments "data", "task_id" in call to "AnalysisWorker"  [call-arg]
src/gui/main_window.py:278: error: "Callable[[], QThread | None]" has no attribute "started"  [attr-defined]
src/gui/main_window.py:282: error: "Callable[[], QThread | None]" has no attribute "quit"  [attr-defined]
src/gui/main_window.py:284: error: "Callable[[], QThread | None]" has no attribute "finished"  [attr-defined]
src/gui/main_window.py:284: error: "Callable[[], QThread | None]" has no attribute "deleteLater"  [attr-defined]
src/gui/main_window.py:285: error: "Callable[[], QThread | None]" has no attribute "start"  [attr-defined]
src/api/main.py:21: error: Argument 2 to "add_exception_handler" of "Starlette" has incompatible type "Callable[[Request, RateLimitExceeded], Response]"; expected "Callable[[Request, Exception], Response | Awaitable[Response]] | Callable[[WebSocket, Exception], Awaitable[None]]"  [arg-type]
Found 40 errors in 16 files (checked 73 source files)
