"""Clinical Compliance Analyzer API\n\nFastAPI backend for the Therapy Compliance Analyzer desktop application.\nProvides endpoints for document analysis, user management, and compliance reporting.\n"""\n\nimport asyncio\nimport logging\nimport sys\nimport time\nfrom collections.abc import Coroutine\nfrom contextlib import asynccontextmanager\nfrom typing import Any\n\nimport numpy as np\nimport structlog\nfrom apscheduler.schedulers.background import BackgroundScheduler\nfrom fastapi import FastAPI, WebSocket, WebSocketDisconnect\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.errors import RateLimitExceeded\nfrom slowapi.util import get_remote_address\nfrom starlette.exceptions import HTTPException as StarletteHTTPException\n\nfrom src.api.dependencies import shutdown_event as api_shutdown\nfrom src.api.dependencies import startup_event as api_startup\nfrom src.api.routers import admin, analysis, auth, chat, compliance, dashboard, feedback, habits, health, meta_analytics, users, rubric_router, individual_habits\n\n# Import new enterprise features\ntry:\n    from src.api.routers import ehr_integration\n\n    EHR_AVAILABLE = True\nexcept ImportError:\n    EHR_AVAILABLE = False\nfrom src.api.global_exception_handler import global_exception_handler, http_exception_handler\nfrom src.config import get_settings\nfrom src.core.vector_store import get_vector_store\nfrom src.database import crud, get_async_db\nfrom src.logging_config import CorrelationIdMiddleware, configure_logging\n\nsettings = get_settings()\nlimiter = Limiter(key_func=get_remote_address, default_limits=["100 per minute"])\n\nlogger = structlog.get_logger(__name__)\n\n# --- WebSocket Log Streaming --- #\n\n\nclass WebSocketManager:\n    """Manages active WebSocket connections."""\n\n    def __init__(self):\n        self.active_connections: list[WebSocket] = []\n\n    async def connect(self, websocket: WebSocket):\n        await websocket.accept()\n        self.active_connections.append(websocket)\n\n    def disconnect(self, websocket: WebSocket):\n        self.active_connections.remove(websocket)\n\n    async def broadcast(self, message: str):\n        for connection in self.active_connections:\n            await connection.send_text(message)\n\n\nlog_manager = WebSocketManager()\nlog_manager = WebSocketManager()\nlog_manager = WebSocketManager()\n\n\nclass WebSocketLogHandler(logging.Handler):\n    """A logging handler that broadcasts log records to WebSockets."""\n\n    def emit(self, record):\n        log_entry = self.format(record)\n        asyncio.run_coroutine_threadsafe(log_manager.broadcast(log_entry), self.loop)\n\n\n# --- In-Memory Task Purging --- #\n# --- In-Memory Task Purging --- #\n# --- In-Memory Task Purging --- #\n\n\nclass InMemoryTaskPurgeService:\n    """A service to purge expired tasks from the in-memory task dictionary."""\n\n    def __init__(self, tasks=None, retention_period_minutes=60, purge_interval_seconds=300):\n        self.tasks = tasks or {}\n        self.retention_period_minutes = retention_period_minutes\n        self.purge_interval_seconds = purge_interval_seconds\n        self._stop_event = asyncio.Event()\n\n    def start(self) -> Coroutine[Any, Any, None]:\n        logger.info("Starting in-memory task purge service.")\n        return asyncio.create_task(self.purge_expired_tasks())\n\n    def stop(self) -> None:\n        logger.info("Stopping in-memory task purge service.")\n        self._stop_event.set()\n\n    async def purge_expired_tasks(self):\n        """Purge expired tasks from memory."""\n        while not self._stop_event.is_set():\n            try:\n                # Simple purge logic - remove old tasks\n                current_time = time.time()\n                expired_keys = [\n                    key\n                    for key, task in self.tasks.items()\n                    if current_time - task.get("created_at", 0) > (self.retention_period_minutes * 60)\n                ]\n                for key in expired_keys:\n                    self.tasks.pop(key, None)\n\n                await asyncio.sleep(self.purge_interval_seconds)\n            except Exception as e:\n                logger.error(f"Error in task purge: {e}")\n                await asyncio.sleep(60)  # Wait before retrying\n\n\n# --- Maintenance Jobs --- #\n# --- Maintenance Jobs --- #\n# --- Maintenance Jobs --- #\n\n\ndef run_maintenance_jobs():\n    """Instantiates and runs all scheduled maintenance services."""\n    # ... (maintenance logic)\n\n\nscheduler = BackgroundScheduler(daemon=True)\nscheduler = BackgroundScheduler(daemon=True)\nscheduler = BackgroundScheduler(daemon=True)\nin_memory_task_purge_service = InMemoryTaskPurgeService(\n    tasks=analysis.tasks,\n    retention_period_minutes=settings.maintenance.in_memory_retention_minutes,\n    purge_interval_seconds=settings.maintenance.in_memory_purge_interval_seconds,\n)\n\n# --- Vector Store Initialization ---\n\n\nasync def initialize_vector_store():\n    """Initializes and populates the vector store on application startup."""\n    vector_store = get_vector_store()\n    if vector_store.is_initialized:\n        return\n\n    vector_store.initialize_index()\n    logger.info("Populating vector store with existing report embeddings...")\n\n    db_session_gen = get_async_db()\n    db = await db_session_gen.__anext__()\n    try:\n        reports = await crud.get_all_reports_with_embeddings(db)\n        if reports:\n            embeddings = [np.frombuffer(report.document_embedding, dtype=np.float32) for report in reports]\n            report_ids = [report.id for report in reports]\n\n            # Ensure all embeddings have the same dimension\n            embedding_dim = embeddings[0].shape[0]\n            valid_embeddings = [emb for emb in embeddings if emb.shape[0] == embedding_dim]\n            valid_ids = [id for emb, id in zip(embeddings, report_ids, strict=False) if emb.shape[0] == embedding_dim]\n\n            if valid_embeddings:\n                vector_store.add_vectors(np.array(valid_embeddings), valid_ids)\n            logger.info("Successfully populated vector store with %s embeddings.", len(valid_embeddings))\n        else:\n            logger.info("No existing reports with embeddings found to populate vector store.")\n    finally:\n        await db.close()\n\n\n# --- Application Lifespan --- #\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    """Lifespan context manager for startup and shutdown events."""\n    configure_logging(settings.log_level)\n    if "pytest" not in sys.modules:\n        ws_handler = WebSocketLogHandler()\n        ws_handler.setLevel(logging.INFO)\n        formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")\n        ws_handler.setFormatter(formatter)\n        logging.getLogger().addHandler(ws_handler)\n\n    await api_startup()\n    await initialize_vector_store()\n\n    run_maintenance_jobs()\n    scheduler.add_job(run_maintenance_jobs, "interval", days=1)\n    scheduler.start()\n    logger.info("Scheduler started for daily maintenance tasks.")\n\n    in_memory_task_purge_service.start()\n\n    yield\n\n    await api_shutdown()\n    scheduler.shutdown()\n    in_memory_task_purge_service.stop()\n\n\n# --- FastAPI App Initialization --- #\n\napp = FastAPI(\n    title="Therapy Compliance Analyzer API",\n    description="...",\n    version="1.0.0",\n    lifespan=lifespan,\n    # ... (other app config)\n)\n\napp.add_middleware(CorrelationIdMiddleware)\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\napp.add_exception_handler(StarletteHTTPException, http_exception_handler)\napp.add_exception_handler(Exception, global_exception_handler)\n\n# --- Routers --- #\n\napp.include_router(health.router, tags=["Health"])\napp.include_router(auth.router, prefix="/auth", tags=["Authentication"])\napp.include_router(admin.router, prefix="/admin", tags=["Admin"])\napp.include_router(analysis.router, tags=["Analysis"])\napp.include_router(analysis.legacy_router, tags=["Analysis Legacy"])\napp.include_router(dashboard.router, prefix="/dashboard", tags=["Dashboard"])\napp.include_router(chat.router, prefix="/chat", tags=["Chat"])\napp.include_router(compliance.router, tags=["Compliance"])\napp.include_router(habits.router, tags=["Habits"])\napp.include_router(meta_analytics.router, tags=["Meta Analytics"])\napp.include_router(feedback.router)\napp.include_router(users.router, tags=["Users"])\napp.include_router(rubric_router.router, prefix="/rubrics", tags=["Rubrics"])\napp.include_router(individual_habits.router)\n\n# Include enterprise features if available\nif EHR_AVAILABLE:\n    app.include_router(ehr_integration.router, tags=["EHR Integration"])\n    logging.info("EHR Integration API enabled")\n\n\n\n# Include plugin management\ntry:\n    from src.api.routers import plugins\n\n    app.include_router(plugins.router, tags=["Plugin Management"])\n    logging.info("Plugin Management API enabled")\nexcept ImportError:\n    logging.warning("Plugin Management API not available")\n\n# --- WebSocket Endpoint --- #\n\n\n@app.websocket("/ws/logs")\nasync def websocket_endpoint(websocket: WebSocket):\n    await log_manager.connect(websocket)\n    try:\n        while True:\n            await websocket.receive_text()\n    except WebSocketDisconnect:\n        log_manager.disconnect(websocket)\n\n\n# --- Root Endpoint --- #\n\n\n@app.get("/")\ndef read_root():\n    """Root endpoint providing API welcome message."""\n    return {"message": "Welcome to the Clinical Compliance Analyzer API"}\n\n\n@app.get("/ai/status")\nasync def get_ai_status():\n    """Get AI model status (root level endpoint for GUI compatibility)"""\n    return {\n        "status": "ready",\n        "models": {\n            "llm": "loaded",\n            "embeddings": "loaded",\n            "ner": "loaded",\n        },\n        "last_updated": "2025-10-07T16:28:15Z",\n    }\n\n