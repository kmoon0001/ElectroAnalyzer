import logging
import torch
import json
import os
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from src.guideline_service import GuidelineService
from src.utils import load_config
from src.rubric_service import ComplianceRule

logger = logging.getLogger(__name__)

class ComplianceAnalyzer:
    """
    Analyzes documents for compliance using a RAG pipeline with a quantized LLM.
    """

    def __init__(self, guideline_service: GuidelineService = None):
        """
        Initializes the ComplianceAnalyzer.

        Args:
            guideline_service (GuidelineService): An instance of the GuidelineService for retrieving relevant guidelines.
        """
        self.config = load_config()
        generator_model_name = self.config['models']['generator']

        logger.info(f"Initializing ComplianceAnalyzer with model: {generator_model_name}")

        self.guideline_service = guideline_service or GuidelineService()

        # Configure quantization to load the model in 4-bit
        quantization_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.bfloat16
        )

        self.tokenizer = AutoTokenizer.from_pretrained(generator_model_name)
        self.generator_model = AutoModelForCausalLM.from_pretrained(
            generator_model_name,
            quantization_config=quantization_config,
            device_map="auto"
        )

        logger.info(f"Generator LLM '{generator_model_name}' loaded successfully.")

    def analyze_document(self, document_text: str, discipline: str, analysis_mode: str = "llm_only") -> dict:
        """
        Analyzes the document using the RAG pipeline.

        Args:
            document_text (str): The text of the document to analyze.
            discipline (str): The discipline to filter by (e.g., 'pt', 'ot', 'slp').
            analysis_mode (str): The analysis mode ('llm_only' or 'hybrid').

        Returns:
            dict: The compliance analysis report generated by the LLM.
        """
        logger.info(f"Starting compliance analysis with mode: {analysis_mode}...")

        # 1. Retrieve relevant guidelines or rules
        if analysis_mode == "hybrid":
            rules = self._get_rules_for_discipline(discipline)
            if not rules:
                return {"error": "No rules found for the specified discipline."}
            prompt = self._build_hybrid_prompt(document_text, "", rules)
        else: # llm_only
            logger.info("Retrieving relevant guidelines...")
            query = document_text[:512]
            top_k = self.config['retrieval_settings']['similarity_top_k']
            retrieved_guidelines = self.guideline_service.search(query=query, top_k=top_k)
            context = "\n".join([f"- {g['source']}: {g['text']}" for g in retrieved_guidelines])
            with open("src/core/prompt_template.txt", "r") as f:
                prompt_template = f.read()
            prompt = prompt_template.format(context=context, document_text=document_text)

        # 3. Generate the analysis
        logger.info("Generating analysis with the LLM...")
        tokenized_inputs = self.tokenizer(prompt, return_tensors="pt")
        if isinstance(tokenized_inputs, str):
            tokenized_inputs = self.tokenizer.encode_plus(prompt, return_tensors="pt")
        device = next(self.generator_model.parameters()).device
        inputs = {k: v.to(device) for k, v in tokenized_inputs.items()}

        # Generate text with a reasonable max length
        output = self.generator_model.generate(
            **inputs,
            max_new_tokens=512,
            temperature=0.7,
            top_p=0.95,
            do_sample=True
        )

        generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)

        # Extract only the analysis part from the generated text
        analysis_section = generated_text.split("**Analysis:**")[-1].strip()

        logger.info("Compliance analysis finished.")
        try:
            return json.loads(analysis_section)
        except json.JSONDecodeError:
            logger.error("Failed to parse LLM output as JSON.")
            return {"error": "Failed to parse LLM output."}

    def check_ai_systems_health(self):
        """
        Checks the health of the AI systems.
        Returns a tuple of (is_healthy, status_message).
        """
        try:
            # Check if models are loaded (this is a basic check)
            if self.generator_model and self.tokenizer and self.guideline_service:
                # A more robust check would involve a test inference
                return True, "AI Systems: Online"
            else:
                return False, "AI Systems: Offline - Models not loaded"
        except Exception as e:
            return False, f"AI Systems: Error - {e}"

    def _get_rules_for_discipline(self, discipline: str) -> list[ComplianceRule]:
        """
        Loads the compliance rules for a given discipline from the corresponding rubric file.
        """
        from src.rubric_service import RubricService
        rubric_path = f"src/resources/{discipline.lower()}_compliance_rubric.ttl"
        if not os.path.exists(rubric_path):
            logger.warning(f"No specific rubric found for discipline: {discipline}. Falling back to default.")
            # Fallback to a default rubric if the discipline-specific one doesn't exist
            rubric_path = "src/resources/pt_compliance_rubric.ttl"

        if not os.path.exists(rubric_path):
            logger.error(f"Default rubric file not found at: {rubric_path}")
            return []

        rubric_service = RubricService(ontology_path=rubric_path)
        return rubric_service.get_rules()

    def _build_hybrid_prompt(self, document: str, entity_list: str, rules: list[ComplianceRule]) -> str:
        """
        Builds the prompt for the LLM for hybrid analysis.
        """
        rules_text = ""
        for i, rule in enumerate(rules):
            rules_text += f"\n**Rule {i+1}: {rule.issue_title}**\n"
            rules_text += f"- **Detail:** {rule.issue_detail}\n"
            rules_text += f"- **Suggestion:** {rule.suggestion}\n"

        return f"""
You are an expert Medicare compliance officer for a Skilled Nursing Facility (SNF). Your task is to analyze a clinical therapy document for potential compliance risks based on a specific set of rules.

**Clinical Document:**
---
{document}
---

**Extracted Clinical Entities:**
---
{entity_list}
---

**Your Task:**
For each of the following rules, analyze the document and determine if there is a violation. Provide a detailed explanation for each finding.

**Rules to Evaluate:**
---
{rules_text}
---

**Output Format:**
Return the analysis as a JSON object with the following structure:
{{
  "findings": [
    {{
      "rule_id": "<the id of the rule being evaluated>",
      "text": "<text from the original document that contains the finding>",
      "risk": "<description of the compliance risk based on the rule>",
      "suggestion": "<suggestion to mitigate the risk>"
    }}
  ]
}}

**Compliance Analysis:**
```json
"""
