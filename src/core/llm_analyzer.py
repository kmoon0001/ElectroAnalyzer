import logging
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSeq2SeqLM
from src.guideline_service import GuidelineService
from src.utils import load_config

logger = logging.getLogger(__name__)

class LLMComplianceAnalyzer:
    """
    Analyzes documents for compliance using a RAG pipeline with a quantized LLM.
    """

    def __init__(self, guideline_service: GuidelineService = None):
        """
        Initializes the LLMComplianceAnalyzer.

        Args:
            guideline_service (GuidelineService): An instance of the GuidelineService for retrieving relevant guidelines.
        """
        self.config = load_config()
        generator_model_name = self.config['models']['generator']
        summarizer_model_name = self.config['models']['summarizer']

        logger.info(f"Initializing LLMComplianceAnalyzer with generator: {generator_model_name} and summarizer: {summarizer_model_name}")

        self.guideline_service = guideline_service or GuidelineService()

        # Configure quantization to load the generator model in 4-bit
        quantization_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.bfloat16
        )

        self.tokenizer = AutoTokenizer.from_pretrained(generator_model_name)
        self.generator_model = AutoModelForCausalLM.from_pretrained(
            generator_model_name,
            quantization_config=quantization_config
        )
        logger.info(f"Generator LLM '{generator_model_name}' loaded successfully.")

        # Load the summarization model
        self.summarizer_tokenizer = AutoTokenizer.from_pretrained(summarizer_model_name)
        self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(summarizer_model_name)
        logger.info(f"Summarizer model '{summarizer_model_name}' loaded successfully.")

    def analyze_document(self, document_text: str) -> str:
        """
        Analyzes the document using an advanced iterative RAG pipeline.

        Args:
            document_text (str): The text of the document to analyze.

        Returns:
            str: The compliance analysis report generated by the LLM.
        """
        logger.info("Starting iterative compliance analysis...")
        max_iterations = self.config['iterative_retrieval']['max_iterations']
        top_k = self.config['retrieval_settings']['similarity_top_k']

        # Load the iterative prompt template
        with open("src/core/prompt_template_iterative.txt", "r") as f:
            prompt_template = f.read()

        all_retrieved_guidelines = []
        analysis_section = "No analysis could be generated."

        for i in range(max_iterations):
            logger.info(f"Iteration {i+1}/{max_iterations}")

            # 1. Summarize the current context
            if all_retrieved_guidelines:
                context_text = "\n".join([g['text'] for g in all_retrieved_guidelines])
                inputs = self.summarizer_tokenizer(context_text, return_tensors="pt", max_length=1024, truncation=True)
                inputs = {k: v.to(self.summarizer_model.device) for k, v in inputs.items()}
                summary_ids = self.summarizer_model.generate(
                    **inputs,
                    max_length=250,
                    min_length=50,
                    length_penalty=2.0,
                    num_beams=4,
                    early_stopping=True
                )
                context = self.summarizer_tokenizer.decode(summary_ids[0], skip_special_tokens=True)
                logger.info("Context summarization complete.")
            else:
                context = "No guidelines retrieved yet. What specific information is needed for the analysis?"

            # 2. Construct and generate from the prompt
            prompt = prompt_template.format(
                context=context,
                document_text=document_text,
                max_iterations=max_iterations,
                current_iteration=i+1
            )

            tokenized_inputs = self.tokenizer(prompt, return_tensors="pt")
            device = self.generator_model.device if hasattr(self.generator_model, 'device') else next(self.generator_model.parameters()).device
            inputs = {k: v.to(device) for k, v in tokenized_inputs.items()}
            output = self.generator_model.generate(
                **inputs,
                max_new_tokens=512,
                temperature=0.7,
                top_p=0.95,
                do_sample=True
            )
            generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)

            # 3. Check for a new search query
            analysis_section = generated_text.split("**Analysis:**")[-1].strip()
            if "[SEARCH]" in analysis_section:
                new_query = analysis_section.split("[SEARCH]")[-1].strip()
                logger.info(f"LLM requested a new search with query: '{new_query}'")

                # Retrieve new guidelines and add them to the list
                exclude_sources = [g['source'] for g in all_retrieved_guidelines]
                retrieved_guidelines = self.guideline_service.search(query=new_query, top_k=top_k, exclude_sources=exclude_sources)
                if retrieved_guidelines:
                    logger.info(f"Retrieved {len(retrieved_guidelines)} new guidelines.")
                    all_retrieved_guidelines.extend(retrieved_guidelines)
                else:
                    logger.info("New search returned no results.")
            else:
                logger.info("LLM provided a final answer. Ending iterations.")
                break

        logger.info("Compliance analysis finished.")
        return analysis_section

