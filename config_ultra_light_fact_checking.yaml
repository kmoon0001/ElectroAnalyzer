# Ultra-Light Clinical Document Analyzer with Full Fact-Checking
# Maximum performance with complete hallucination reduction mechanisms

# Application Settings
app_name: "Therapy Compliance Analyzer"
version: "2.0.0"
debug: false

# AI Configuration
use_ai_mocks: false  # REAL AI with ultra-light models

# Database Configuration
database:
  url: "sqlite:///./compliance.db"
  echo: false

# LLM Configuration - Meditron 7B Q4_K_S (Ultra-Light)
llm:
  context_length: 4096
  gpu_layers: 0
  threads: 8
  hf_model_type: meditron
  model_type: ctransformers
  model_repo_id: TheBloke/meditron-7B-GGUF
  local_model_path: "models/meditron7b-ultra/meditron-7b.Q4_K_S.gguf"
  generation_params:
    max_new_tokens: 1024
    repeat_penalty: 1.1
    stop_sequences:
    - </analysis>
    - "\n\n---"
    temperature: 0.1  # Low temperature for factual accuracy
    top_p: 0.9

# Fact-Checking Configuration - FULL FEATURES
fact_checking:
  enabled: true
  medical_fact_checker: "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"
  confidence_threshold: 0.7
  cross_reference_sources: true
  validate_medical_terms: true
  check_compliance_rules: true

# Hallucination Reduction - OPTIMIZED
hallucination_reduction:
  enabled: true
  confidence_calibration: true
  uncertainty_detection: true
  source_attribution: true
  medical_dictionary_validation: true
  compliance_rubric_checking: true

# Chat Configuration - With Fact-Checking
chat:
  enabled: true
  model: "dialogpt-medium"
  local_path: "models/dialogpt-medium"
  max_tokens: 256
  temperature: 0.7
  context_length: 512
  response_timeout: 5
  fact_check_responses: true  # Enable fact-checking for chat
  medical_accuracy_mode: true

# Generator Profiles - Ultra-Light with Fact-Checking
generator_profiles:
  clinical_ultra_light:
    name: "Meditron 7B Q4_K_S - Ultra-Light Medical Analysis"
    description: "Ultra-light quantization with full fact-checking"
    generator: "meditron-7b-ultra"
    local_path: "models/meditron7b-ultra"
    repo: "TheBloke/meditron-7B-GGUF"
    model_file: "meditron-7b.Q4_K_S.gguf"
    context_length: 4096
    max_tokens: 1024
    temperature: 0.1
    quantization: "Q4_K_S"
    fact_checking_enabled: true
    hallucination_reduction: true

  chat_light:
    name: "DialoGPT Medium - Lightweight Chat with Fact-Checking"
    description: "Fast conversational AI with medical accuracy"
    generator: "dialogpt-medium"
    local_path: "models/dialogpt-medium"
    repo: "microsoft/DialoGPT-medium"
    context_length: 512
    max_tokens: 256
    temperature: 0.7
    type: "chat"
    fact_checking_enabled: true
    medical_accuracy_mode: true

# NER Models - Ultra-Light with Fact-Checking
ner_models:
  biomedical_ultra:
    name: "Ultra-Distilled Biomedical NER"
    model_id: "d4data/biomedical-ner-all"
    local_path: "models/biomedical-ner-ultra"
    priority: 1
    type: "ultra-distilled"
    size_reduction: "70%"
    fact_checking_enabled: true
    medical_entity_validation: true

# Embedding Models - Ultra-Light Version
embedding_models:
  distilbert_ultra:
    name: "DistilBERT Ultra-Light Embeddings"
    model_id: "sentence-transformers/distilbert-base-nli-mean-tokens"
    local_path: "models/distilbert-ultra"
    dimension: 768
    type: "ultra-distilled"
    size_reduction: "60%"

# Analysis Settings - Optimized for Performance with Accuracy
analysis:
  max_file_size_mb: 50
  supported_formats: ["pdf", "docx", "txt", "html"]
  phi_redaction: true
  confidence_threshold: 0.7
  fact_checking_enabled: true
  hallucination_detection: true
  medical_accuracy_mode: true

# API Settings
api:
  host: "127.0.0.1"
  port: 8001
  cors_origins: ["http://127.0.0.1:3001", "http://localhost:3001"]

# Logging
logging:
  level: "INFO"
  format: "json"
  file: "logs/app.log"

# Cache Settings - Optimized for Performance
cache:
  enabled: true
  ttl_seconds: 7200
  max_size_mb: 500
  fact_check_cache: true  # Cache fact-checking results

# Ultra-Light Performance Settings with Accuracy
ultra_light_mode:
  enabled: true
  single_ner_model: true
  skip_redundant_processing: true
  optimized_batch_size: 8
  max_concurrent_analyses: 8
  memory_optimization: true
  fast_inference: true
  chat_enabled: true
  chat_performance_mode: true
  fact_checking_enabled: true  # Maintain accuracy
  hallucination_reduction_enabled: true

# Fact-Checking Performance Settings
fact_checking_performance:
  enable_caching: true
  parallel_fact_checking: true
  batch_fact_checking: true
  medical_dictionary_cache: true
  compliance_rules_cache: true

# Chat Performance Settings with Accuracy
chat_performance:
  enable_response_caching: true
  max_concurrent_chats: 4
  response_cache_ttl: 300
  fast_response_mode: true
  skip_complex_reasoning: false  # Keep medical accuracy
  fact_check_chat_responses: true

# Performance Monitoring
performance:
  track_inference_time: true
  monitor_memory_usage: true
  log_performance_metrics: true
  track_fact_checking_accuracy: true
  monitor_hallucination_rate: true
  target_inference_time_ms: 2000
  target_chat_response_ms: 1000
  target_fact_check_time_ms: 500

# Resource Optimization
resources:
  max_memory_gb: 4
  cpu_threads: 8
  enable_model_caching: true
  lazy_loading: true
  chat_memory_limit_mb: 512
  fact_checking_memory_limit_mb: 256
