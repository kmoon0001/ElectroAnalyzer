# Ultra-Light Clinical Document Analyzer Configuration
# Maximum performance with minimal resource usage

# Application Settings
app_name: "Therapy Compliance Analyzer"
version: "2.0.0"
debug: false

# AI Configuration
use_ai_mocks: false  # REAL AI with ultra-light models

# Database Configuration
database:
  url: "sqlite:///./compliance.db"
  echo: false

# LLM Configuration - Meditron 7B Q4_K_S (Ultra-Light)
llm:
  context_length: 4096
  gpu_layers: 0
  threads: 8  # Increased for better performance
  hf_model_type: meditron
  model_type: ctransformers
  model_repo_id: TheBloke/meditron-7B-GGUF
  local_model_path: "models/meditron7b-ultra/meditron-7b.Q4_K_S.gguf"
  generation_params:
    max_new_tokens: 1024
    repeat_penalty: 1.1
    stop_sequences:
    - </analysis>
    - "\n\n---"
    temperature: 0.1
    top_p: 0.9

# Generator Profiles - Ultra-Light Models
generator_profiles:
  clinical_ultra_light:
    name: "Meditron 7B Q4_K_S - Ultra-Light Medical Analysis"
    description: "Ultra-light quantization for maximum performance"
    generator: "meditron-7b-ultra"
    local_path: "models/meditron7b-ultra"
    repo: "TheBloke/meditron-7B-GGUF"
    model_file: "meditron-7b.Q4_K_S.gguf"
    context_length: 4096
    max_tokens: 1024
    temperature: 0.1
    quantization: "Q4_K_S"
    performance_improvement: "25% smaller, 2x faster"

# NER Models - Single Ultra-Light Model Only
ner_models:
  biomedical_ultra:
    name: "Ultra-Distilled Biomedical NER"
    model_id: "d4data/biomedical-ner-all"
    local_path: "models/biomedical-ner-ultra"
    priority: 1
    type: "ultra-distilled"
    size_reduction: "70%"
    # Removed OpenMed NER - redundant for performance

# Embedding Models - Ultra-Light Version
embedding_models:
  distilbert_ultra:
    name: "DistilBERT Ultra-Light Embeddings"
    model_id: "sentence-transformers/distilbert-base-nli-mean-tokens"
    local_path: "models/distilbert-ultra"
    dimension: 768
    type: "ultra-distilled"
    size_reduction: "60%"

# Analysis Settings - Optimized for Performance
analysis:
  max_file_size_mb: 50
  supported_formats: ["pdf", "docx", "txt", "html"]
  phi_redaction: true
  confidence_threshold: 0.7

# API Settings
api:
  host: "127.0.0.1"
  port: 8001
  cors_origins: ["http://127.0.0.1:3001", "http://localhost:3001"]

# Logging
logging:
  level: "INFO"
  format: "json"
  file: "logs/app.log"

# Cache Settings - Optimized for Performance
cache:
  enabled: true
  ttl_seconds: 7200  # Longer cache for performance
  max_size_mb: 500   # Smaller cache for memory efficiency

# Ultra-Light Performance Settings
ultra_light_mode:
  enabled: true
  single_ner_model: true  # Use only biomedical NER
  skip_redundant_processing: true
  optimized_batch_size: 8  # Larger batches for efficiency
  max_concurrent_analyses: 8  # More concurrent for speed
  memory_optimization: true
  fast_inference: true

# Performance Monitoring
performance:
  track_inference_time: true
  monitor_memory_usage: true
  log_performance_metrics: true
  target_inference_time_ms: 2000  # 2 second target

# Resource Optimization
resources:
  max_memory_gb: 4  # Limit memory usage
  cpu_threads: 8    # Optimize CPU usage
  enable_model_caching: true
  lazy_loading: true  # Load models only when needed
